{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! sed 's/\\r//g' data/ai.ja.txt | cabocha -f1 > data/ai.ja.cabocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ginza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sed 's/\\r//g' data/ai.ja.txt | ginza -f cabocha > data/ai.ja.cabocha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40. 係り受け解析結果の読み込み（形態素）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morph:\n",
    "    def __init__(self, line):\n",
    "        line = line.split('\\t')\n",
    "        self.surface = line[0]\n",
    "        features = line[1].split(',')\n",
    "        self.base = features[6]\n",
    "        self.pos = features[0]\n",
    "        self.pos1 = features[1]\n",
    "        self.pos2 = features[2]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ai.ja.cabocha') as f:\n",
    "    data = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "sentence = []\n",
    "for line in data:\n",
    "    if line == 'EOS':\n",
    "        if sentence: # cabochaだと\"EOS\\nEOS\" が文の区切りになるので必要\n",
    "            text.append(sentence)\n",
    "            sentence = []\n",
    "    elif line != '' and (not line.startswith('*')):\n",
    "        morph = Morph(line)\n",
    "        sentence.append(morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ジョン,\n",
       " ・,\n",
       " マッカーシー,\n",
       " は,\n",
       " AI,\n",
       " に,\n",
       " 関する,\n",
       " 最初,\n",
       " の,\n",
       " 会議,\n",
       " で,\n",
       " 「,\n",
       " 人工知能,\n",
       " 」,\n",
       " と,\n",
       " いう,\n",
       " 用語,\n",
       " を,\n",
       " 作り出し,\n",
       " た,\n",
       " 。]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41. 係り受け解析結果の読み込み（文節・係り受け）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk(list):\n",
    "    def __init__(self, dst):\n",
    "        super().__init__()\n",
    "        self.dst = dst\n",
    "        self.srcs = []\n",
    "    \n",
    "    def __repr__(self): # 問42で使う\n",
    "        return re.sub(r'[、。]', '', ''.join(map(str, self)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence(list):\n",
    "    def __init__(self, chunks):\n",
    "        super().__init__(chunks)\n",
    "        for i, chunk in enumerate(self):\n",
    "            if chunk.dst != -1:\n",
    "                self[chunk.dst].srcs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text(list):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sentence = []\n",
    "        self.chunk = None\n",
    "        \n",
    "    def new_chunk(self, line):\n",
    "        if self.chunk is not None:\n",
    "            self.sentence.append(self.chunk)\n",
    "        dst = int(line.split()[2].replace('D', ''))\n",
    "        self.chunk = Chunk(dst)\n",
    "        \n",
    "    def new_morph(self, line):\n",
    "        morph = Morph(line)\n",
    "        self.chunk.append(morph)\n",
    "        \n",
    "    def end_sentence(self):\n",
    "        if self.chunk is not None: # EOSが連続する場合があるため\n",
    "            self.sentence.append(self.chunk)\n",
    "            self.append(Sentence(self.sentence))\n",
    "            self.sentence = []\n",
    "        self.chunk = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text()\n",
    "for line in data:\n",
    "    if line == 'EOS':\n",
    "        text.end_sentence()\n",
    "    elif line == '':\n",
    "        pass\n",
    "    elif line.startswith('*'):\n",
    "        text.new_chunk(line)\n",
    "    else:\n",
    "        text.new_morph(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ジョン・マッカーシーは, AIに関する, 最初の, 会議で, 「人工知能」という, 用語を, 作り出した]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  番号</th><th>文節                  </th><th style=\"text-align: right;\">  係り先</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">     0</td><td>ジョン・マッカーシーは</td><td style=\"text-align: right;\">       6</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     1</td><td>AIに関する            </td><td style=\"text-align: right;\">       3</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     2</td><td>最初の                </td><td style=\"text-align: right;\">       3</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     3</td><td>会議で                </td><td style=\"text-align: right;\">       6</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     4</td><td>「人工知能」という    </td><td style=\"text-align: right;\">       5</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     5</td><td>用語を                </td><td style=\"text-align: right;\">       6</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     6</td><td>作り出した            </td><td style=\"text-align: right;\">      -1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: right;\">  番号</th><th>文節                  </th><th style=\"text-align: right;\">  係り先</th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: right;\">     0</td><td>ジョン・マッカーシーは</td><td style=\"text-align: right;\">       6</td></tr>\\n<tr><td style=\"text-align: right;\">     1</td><td>AIに関する            </td><td style=\"text-align: right;\">       3</td></tr>\\n<tr><td style=\"text-align: right;\">     2</td><td>最初の                </td><td style=\"text-align: right;\">       3</td></tr>\\n<tr><td style=\"text-align: right;\">     3</td><td>会議で                </td><td style=\"text-align: right;\">       6</td></tr>\\n<tr><td style=\"text-align: right;\">     4</td><td>「人工知能」という    </td><td style=\"text-align: right;\">       5</td></tr>\\n<tr><td style=\"text-align: right;\">     5</td><td>用語を                </td><td style=\"text-align: right;\">       6</td></tr>\\n<tr><td style=\"text-align: right;\">     6</td><td>作り出した            </td><td style=\"text-align: right;\">      -1</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = [(chunk, chunk.dst) for chunk in text[33]]\n",
    "\n",
    "tabulate(table, tablefmt = 'html', headers = ['番号', '文節', '係り先'], showindex = 'always')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42. 係り元と係り先の文節の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ジョン・マッカーシーは\t作り出した\n",
      "AIに関する\t会議で\n",
      "最初の\t会議で\n",
      "会議で\t作り出した\n",
      "「人工知能」という\t用語を\n",
      "用語を\t作り出した\n"
     ]
    }
   ],
   "source": [
    "sent = text[33]\n",
    "\n",
    "for chunk in sent:\n",
    "    if chunk.dst != -1:\n",
    "        src = chunk\n",
    "        dst = sent[chunk.dst]\n",
    "        print('{}\\t{}'.format(src, dst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43. 名詞を含む文節が動詞を含む文節に係るものを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_noun(chunk):\n",
    "    return any(morph.pos == '名詞' for morph in chunk)\n",
    "\n",
    "def has_verb(chunk):\n",
    "    return any(morph.pos == '動詞' for morph in chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ジョン・マッカーシーは\t作り出した\n",
      "会議で\t作り出した\n",
      "用語を\t作り出した\n"
     ]
    }
   ],
   "source": [
    "sent = text[33]\n",
    "\n",
    "for chunk in sent:\n",
    "    if chunk.dst != -1 and has_noun(chunk) and has_verb(sent[chunk.dst]):\n",
    "        src = chunk\n",
    "        dst = sent[chunk.dst]\n",
    "        print('{}\\t{}'.format(src, dst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 44. 係り受け木の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"535pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 534.68 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 530.6817,-184 530.6817,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"112.44\" cy=\"-90\" rx=\"112.3801\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.44\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ジョン・マッカーシーは</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"281.44\" cy=\"-18\" rx=\"57.3905\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.44\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">作り出した</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M152.063,-73.1192C177.7826,-62.1618 211.3162,-47.8752 237.7985,-36.5928\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.3805,-39.7233 247.2085,-32.5838 236.6368,-33.2834 239.3805,-39.7233\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"167.44\" cy=\"-162\" rx=\"57.3905\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"167.44\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">AIに関する</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"281.44\" cy=\"-90\" rx=\"38.1938\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.44\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">会議で</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M193.0238,-145.8418C209.6827,-135.3204 231.5479,-121.5108 249.3663,-110.2571\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"251.6804,-112.9352 258.2663,-104.636 247.9424,-107.0168 251.6804,-112.9352\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"281.44\" cy=\"-162\" rx=\"38.1938\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.44\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">最初の</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M281.44,-143.8314C281.44,-136.131 281.44,-126.9743 281.44,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"284.9401,-118.4132 281.44,-108.4133 277.9401,-118.4133 284.9401,-118.4132\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;6 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M281.44,-71.8314C281.44,-64.131 281.44,-54.9743 281.44,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"284.9401,-46.4132 281.44,-36.4133 277.9401,-46.4133 284.9401,-46.4132\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"432.44\" cy=\"-162\" rx=\"94.4839\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"432.44\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">「人工知能」という</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"404.44\" cy=\"-90\" rx=\"38.1938\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"404.44\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">用語を</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M425.3744,-143.8314C422.2669,-135.8406 418.5496,-126.2819 415.1156,-117.4514\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"418.2929,-115.9649 411.4063,-107.9134 411.7689,-118.502 418.2929,-115.9649\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M380.4324,-75.9468C362.5277,-65.4659 337.767,-50.9719 317.4889,-39.1018\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"319.216,-36.0572 308.8177,-34.0259 315.6797,-42.0983 319.216,-36.0572\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc148ab57f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = text[33]\n",
    "\n",
    "G = Digraph(format='svg')\n",
    "\n",
    "# 節を作る\n",
    "for i, chunk in enumerate(sent):\n",
    "    G.node(str(i), str(chunk))\n",
    "    \n",
    "# 枝を作る\n",
    "for i, chunk in enumerate(sent):\n",
    "    if chunk.dst != -1:\n",
    "        G.edge(str(i), str(chunk.dst))\n",
    "    \n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 45. 動詞の格パターンの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_verb(chunk):\n",
    "    for morph in chunk:\n",
    "        if morph.pos == '動詞':\n",
    "            return morph.base\n",
    "\n",
    "def get_last_case(chunk):\n",
    "    for morph in chunk[::-1]:\n",
    "        if morph.pos == '助詞':\n",
    "            return morph.surface\n",
    "        \n",
    "def extract_case_patterns(sent):\n",
    "    patterns = []\n",
    "    for chunk in sent:\n",
    "        if verb := get_first_verb(chunk): # チャンク最初の動詞\n",
    "            srcs = [sent[src] for src in chunk.srcs]\n",
    "            cases = [case for src in srcs if (case := get_last_case(src))] # 係り元のチャンクの最後の助詞\n",
    "            if cases:\n",
    "                patterns.append((verb, cases))\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('result/case_pattern.txt', 'w') as f:\n",
    "    for sent in text:\n",
    "        patterns = extract_case_patterns(sent)\n",
    "        for verb, cases in patterns:\n",
    "            line = '{}\\t{}'.format(verb, ' '.join(cases))\n",
    "            print(line, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     51 する\tを\r\n",
      "     22 する\tと\r\n",
      "     17 する\tが\r\n",
      "     16 する\tは を\r\n",
      "     10 する\tに\r\n",
      "     10 する\tて を\r\n",
      "      9 よる\tの\r\n",
      "      8 する\tは と\r\n",
      "      7 行う\tを\r\n",
      "      7 する\tは\r\n"
     ]
    }
   ],
   "source": [
    "! cat result/case_pattern.txt | sort | uniq -c | sort -nr 2> /dev/null | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     51 する\tを\r\n",
      "     22 する\tと\r\n",
      "     17 する\tが\r\n",
      "     16 する\tは を\r\n",
      "     10 する\tに\r\n",
      "     10 する\tて を\r\n",
      "      8 する\tは と\r\n",
      "      7 する\tは\r\n",
      "      7 する\tて\r\n",
      "      6 する\tは が\r\n"
     ]
    }
   ],
   "source": [
    "! cat result/case_pattern.txt | grep 'する' | sort | uniq -c | sort -nr 2> /dev/null | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1 見る\tを て から\r\n",
      "      1 見る\tは も\r\n",
      "      1 見る\tが\r\n"
     ]
    }
   ],
   "source": [
    "! cat result/case_pattern.txt | grep '見る' | sort | uniq -c | sort -nr 2> /dev/null | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1 与える\tは に を\r\n",
      "      1 与える\tが に\r\n",
      "      1 与える\tが\r\n"
     ]
    }
   ],
   "source": [
    "! cat result/case_pattern.txt | grep '与える' | sort | uniq -c | sort -nr 2> /dev/null | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 46. 動詞の格フレーム情報の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_args(srcs):\n",
    "    cases = []\n",
    "    args = []\n",
    "    for src in srcs:\n",
    "        if case := get_last_case(src): # 係り元のチャンクの最後の助詞\n",
    "            cases.append(case)\n",
    "            args.append(str(src))\n",
    "    return cases, args\n",
    "\n",
    "def extract_case_frames(sent):\n",
    "    frames = []\n",
    "    for chunk in sent:\n",
    "        if verb := get_first_verb(chunk): # チャンク最初の動詞\n",
    "            srcs = [sent[src] for src in chunk.srcs]\n",
    "            cases, args = extract_args(srcs)\n",
    "            if cases:\n",
    "                frames.append((verb, cases, args))\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "いう\tは\tAI〈エーアイ〉）とは\n",
      "いう\tと\t「『計算（）』という概念と\n",
      "用いる\tを\t『コンピュータ（）』という道具を\n",
      "する\tて を\t用いて 『知能』を\n",
      "指す\tを\t一分野」を\n",
      "代わる\tを に\t知的行動を 人間に\n",
      "行う\tて に\t代わって コンピューターに\n",
      "関する\tや\t設計や\n",
      "する\tも\t研究分野」とも\n",
      "述べる\tで は\t解説で 佐藤理史は\n",
      "する\tを で\t知的能力を コンピュータ上で\n",
      "する\tを\t推論・判断を\n",
      "する\tを\t画像データを\n",
      "する\tて を\t解析して パターンを\n",
      "する\tたり\t検出・抽出したり\n",
      "ある\tは が\t応用例は 画像認識等が\n",
      "する\tに で に\t1956年に ダートマス会議で ジョン・マッカーシーにより\n",
      "用いる\tを\t記号処理を\n",
      "する\tを と\t記述を 主体と\n",
      "いう\tの\t研究での\n",
      "使う\tは も\t現在では 意味あいでも\n",
      "呼ぶ\tも\t思考ルーチンも\n",
      "する\tを\tカウンセラーを\n",
      "出す\tが に\tプログラム（人工無脳）が 引き合いに\n",
      "する\tに を\t計算機に 役割を\n",
      "呼ぶ\tと\t「エキスパートシステム」と\n",
      "持つ\tが に\t人間が 暗黙に\n",
      "なる\tが と\t記述が 問題と\n",
      "する\tが は\t出されるが 実現は\n"
     ]
    }
   ],
   "source": [
    "for sent in text[:10]:\n",
    "    frames = extract_case_frames(sent)\n",
    "    for verb, cases, args in frames:\n",
    "        line = '{}\\t{}\\t{}'.format(verb, ' '.join(cases), ' '.join(args))\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 47. 機能動詞構文のマイニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sahen(chunk):\n",
    "    return len(chunk) == 2 and chunk[0].pos2 == 'サ変可能' and chunk[1].surface == 'を'\n",
    "\n",
    "def split_sahen(srcs):\n",
    "    for i in range(len(srcs)):\n",
    "        if is_sahen(srcs[i]):\n",
    "            return str(srcs[i]), srcs[:i] + srcs[i+1:]\n",
    "    return None, srcs\n",
    "\n",
    "def extract_sahen_frames(sent):\n",
    "    frames = []\n",
    "    for chunk in sent:\n",
    "        if verb := get_first_verb(chunk):\n",
    "            srcs = [sent[src] for src in chunk.srcs]\n",
    "            sahen, rest = split_sahen(srcs)\n",
    "            cases, args = extract_args(srcs)\n",
    "            if sahen and cases:\n",
    "                frames.append((sahen + verb, cases, args))\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result/sahen_frames.txt', 'w') as f:\n",
    "    for sent in text:\n",
    "        frames = extract_sahen_frames(sent)\n",
    "        for sahen_verb, cases, args in frames:\n",
    "            line = '{}\\t{}\\t{}'.format(sahen_verb, ' '.join(cases), ' '.join(args))\n",
    "            print(line, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 注目を集める\r\n",
      "      2 研究をする\r\n",
      "      2 運転をする\r\n",
      "      1 話をする\r\n",
      "      1 流行を超える\r\n",
      "      1 命令をする\r\n",
      "      1 普及を受ける\r\n",
      "      1 反乱を起こす\r\n",
      "      1 判断を介す\r\n",
      "      1 投資を行う\r\n"
     ]
    }
   ],
   "source": [
    "! cat result/sahen_frames.txt | cut -f 1 | sort | uniq -c | sort -nr 2> /dev/null | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1 話をする\tば は を\r\n",
      "      1 流行を超える\tを\r\n",
      "      1 命令をする\tを で\r\n",
      "      1 普及を受ける\tを\r\n",
      "      1 反乱を起こす\tて て を\r\n",
      "      1 判断を介す\tを\r\n",
      "      1 投資を行う\tで を\r\n",
      "      1 投資をする\tは を に を\r\n",
      "      1 展開を変える\tを\r\n",
      "      1 追及を受ける\tて は に で を\r\n"
     ]
    }
   ],
   "source": [
    "! cat result/sahen_frames.txt | cut -f 1,2 | sort | uniq -c | sort -nr 2> /dev/null | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 48. 名詞から根へのパスの抽出 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace(n, sent):\n",
    "    path = []\n",
    "    while n != -1:\n",
    "        path.append(n)\n",
    "        n = sent[n].dst\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ジョン・マッカーシーは -> 作り出した\n",
      "AIに関する -> 会議で -> 作り出した\n",
      "最初の -> 会議で -> 作り出した\n",
      "会議で -> 作り出した\n",
      "「人工知能」という -> 用語を -> 作り出した\n",
      "用語を -> 作り出した\n"
     ]
    }
   ],
   "source": [
    "sent = text[33]\n",
    "heads = [n for n in range(len(sent)) if has_noun(sent[n])]\n",
    "for head in heads:\n",
    "    path = trace(head, sent)\n",
    "    path = ' -> '.join([str(sent[n]) for n in path])\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 49. 名詞間の係り受けパスの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_path(x, y, sent):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    while x != y:\n",
    "        if x < y:\n",
    "            xs.append(x)\n",
    "            x = sent[x].dst\n",
    "        else:\n",
    "            ys.append(y)\n",
    "            y = sent[y].dst\n",
    "    return xs, ys, x\n",
    "\n",
    "def remove_initial_nouns(chunk):\n",
    "    for i, morph in enumerate(chunk):\n",
    "        if morph.pos != '名詞' and morph.pos != '補助記号':\n",
    "            break\n",
    "    return ''.join([str(morph) for morph in chunk[i:]]).strip()\n",
    "\n",
    "def path_to_str(xs, ys, last, sent):\n",
    "    xs = [sent[x] for x in xs]\n",
    "    ys = [sent[y] for y in ys]\n",
    "    last = sent[last]\n",
    "    if xs and ys:\n",
    "        xs = ['X' + remove_initial_nouns(xs[0])] + [str(x) for x in xs[1:]]\n",
    "        ys = ['Y' + remove_initial_nouns(ys[0])] + [str(y) for y in ys[1:]]\n",
    "        last = str(last)\n",
    "        return ' -> '.join(xs) + ' | ' + ' -> '.join(ys) + ' | ' + last\n",
    "    else:\n",
    "        xs = xs + ys\n",
    "        xs = ['X' + remove_initial_nouns(xs[0])] + [str(x) for x in xs[1:]]\n",
    "        last = 'Y' + remove_initial_nouns(last)\n",
    "        return ' -> '.join(xs + [last])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パスの先頭: [0, 1, 2, 3, 4, 5]\n",
      "パスの先頭のペア:  [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5)]\n",
      "係り受けのパス:\n",
      "Xは | Yに関する -> 会議で | 作り出した\n",
      "Xは | Yの -> 会議で | 作り出した\n",
      "Xは | Yで | 作り出した\n",
      "Xは | Yという -> 用語を | 作り出した\n",
      "Xは | Yを | 作り出した\n",
      "Xに関する | Yの | 会議で\n",
      "Xに関する -> Yで\n",
      "Xに関する -> 会議で | Yという -> 用語を | 作り出した\n",
      "Xに関する -> 会議で | Yを | 作り出した\n",
      "Xの -> Yで\n",
      "Xの -> 会議で | Yという -> 用語を | 作り出した\n",
      "Xの -> 会議で | Yを | 作り出した\n",
      "Xで | Yという -> 用語を | 作り出した\n",
      "Xで | Yを | 作り出した\n",
      "Xという -> Yを\n"
     ]
    }
   ],
   "source": [
    "sent = text[33]\n",
    "\n",
    "heads = [n for n in range(len(sent)) if has_noun(sent[n])]\n",
    "print('パスの先頭:', heads)\n",
    "\n",
    "pairs = [\n",
    "    (heads[n], second)\n",
    "    for n in range(len(heads))\n",
    "    for second in heads[n + 1:]]\n",
    "print('パスの先頭のペア: ', pairs)\n",
    "\n",
    "print('係り受けのパス:')\n",
    "for x, y in pairs:\n",
    "    x_path, y_path, last = extract_path(x, y, sent)\n",
    "    path = path_to_str(x_path, y_path, last, sent)\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
